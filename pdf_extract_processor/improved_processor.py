"""
–£–ª—É—á—à–µ–Ω–Ω—ã–π PDF –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä —Å –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω–æ–π –ª–æ–≥–∏–∫–æ–π OCR
–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –≤—Å–µ—Ö —É–ª—É—á—à–µ–Ω–∏–π –∏–∑ –Ω–æ—É—Ç–±—É–∫–∞
"""

import os
import re
import numpy as np
from PIL import Image, ImageEnhance
import pytesseract
import fitz
from datetime import datetime
from io import BytesIO

from .main_processor import AdvancedPDFExtractProcessor, QualityLevel

class ImprovedTextCorrector:
    """–£–ª—É—á—à–µ–Ω–Ω–∞—è –∫–æ—Ä—Ä–µ–∫—Ü–∏—è OCR –æ—à–∏–±–æ–∫"""
    
    def __init__(self):
        self.word_fixes = {
            '–ú–ò–ù–ò–°–¢–ï–†–°–¢–í–û': ['–ú–ò–ù–ô–°–¢–ï–†–°–¢–í–û', '–ú–ò–ò–ò–°–¢–ï–†–°–¢–í–û', '–ú–ò–ù–ò–°–¢–ï–†–°–¢–í0'],
            '–ó–î–†–ê–í–û–û–•–†–ê–ù–ï–ù–ò–Ø': ['–ó–î–†–ê–í–û–•–†–ê–ù–ï–ù–ò–Ø', '–ó–î–†–ê–í–û–û–•–†–ê–ù–ï–ù1–Ø'],
            '–†–û–°–°–ò–ô–°–ö–û–ô': ['–†–û–°–°–ò–ò–°–ö–û–ô', '–†–û–°–°–ù–ô–°–ö–û–ô', '–†–û–°–°–ò–ô–°–ö–û–ò'],
            '–§–ï–î–ï–†–ê–¶–ò–ò': ['–§–ï–î–ï–†–ê–¶–ô–ò', '–§–ï–î–ï–†–ê–¶–ò1', '–§–ï–î–ï–†–ê–ù–ò–ò'],
            '–ü–†–ò–ö–ê–ó': ['–ü–†1–ö–ê–ó', '–ü–†–ô–ö–ê–ó', '–ü–†–ò–ö–ê–ó¬©'],
        }
        
        self.char_fixes = {
            'Pe Seg': '', 'or¬´': '', '¬•': '', '‚Ññ J': '‚Ññ',
            '$': '', '[': '', ']': '', '¬©': '–û',
            '2–û': '20',  # –ö–†–ò–¢–ò–ß–ù–û: 2–û11 ‚Üí 2011
            '6–û': '60', '1–û': '10', '3–û': '30',
        }
    
    def improved_fix(self, text: str) -> str:
        """–ü—Ä–∏–º–µ–Ω–∏—Ç—å –≤—Å–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è"""
        if not text or not text.strip():
            return text
        
        result = text
        
        # –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è –¥–∞—Ç
        result = re.sub(r'2–û(\\d{2})', r'20\\1', result)
        result = re.sub(r'(\\d)–û(\\d)', r'\\g<1>0\\2', result)
        
        # –°–ª–æ–≤–∞—Ä–Ω—ã–µ –∑–∞–º–µ–Ω—ã
        for correct, errors in self.word_fixes.items():
            for error in errors:
                result = result.replace(error, correct)
        
        # –°–∏–º–≤–æ–ª—å–Ω—ã–µ –∑–∞–º–µ–Ω—ã
        for wrong, right in self.char_fixes.items():
            result = result.replace(wrong, right)
        
        # –û—á–∏—Å—Ç–∫–∞
        result = re.sub(r'\\s+', ' ', result)
        return result.strip()

class ImprovedAdvancedPDFExtractProcessor(AdvancedPDFExtractProcessor):
    """
    –£–õ–£–ß–®–ï–ù–ù–ê–Ø –≤–µ—Ä—Å–∏—è –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞ —Å –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω–æ–π –ª–æ–≥–∏–∫–æ–π
    """
    
    def __init__(self):
        super().__init__()
        self.text_corrector = ImprovedTextCorrector()
        print("‚úÖ –£–ª—É—á—à–µ–Ω–Ω—ã–π –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä –≥–æ—Ç–æ–≤")
    
    def process_single_file_advanced(self, file_path: str) -> str:
        """–ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Å –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π —Å—Ç—Ä–∞—Ç–µ–≥–∏–µ–π"""
        try:
            print("üîç –ê–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞...")
            quality_level, confidence, method = self.quality_analyzer.analyze_pdf_quality(file_path)
            
            print(f"   üìä –ö–∞—á–µ—Å—Ç–≤–æ: {quality_level.value}")
            print(f"   üìà –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {confidence:.3f}")
            print(f"   üéØ –ú–µ—Ç–æ–¥: {method}")
            
            # –ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –õ–û–ì–ò–ö–ê - –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—é!
            if method == "text_extraction":
                extracted_text = self._extract_text_simple(file_path)
            elif method in ["ocr_simple", "ocr_enhanced", "ocr_advanced"]:
                extracted_text = self._extract_text_ocr_improved(file_path)
            else:
                extracted_text = self._extract_text_ocr_improved(file_path)
            
            # –ü—Ä–∏–º–µ–Ω—è–µ–º –∫–æ—Ä—Ä–µ–∫—Ü–∏—é
            if extracted_text:
                corrected_text = self.text_corrector.improved_fix(extracted_text)
                return self._create_improved_markdown(corrected_text, file_path, quality_level, confidence, method)
            else:
                return self._create_error_result(file_path, "–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å —Ç–µ–∫—Å—Ç")
                
        except Exception as e:
            return self._create_error_result(file_path, f"–û—à–∏–±–∫–∞: {e}")
    
    def _extract_text_simple(self, file_path: str) -> str:
        """–ü—Ä–æ—Å—Ç–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞"""
        try:
            doc = fitz.open(file_path)
            full_text = ""
            
            for page_num in range(len(doc)):
                page = doc[page_num]
                text = page.get_text()
                if text.strip():
                    full_text += f"\\n--- –°—Ç—Ä–∞–Ω–∏—Ü–∞ {page_num + 1} ---\\n{text}"
            
            doc.close()
            return full_text.strip()
        except Exception:
            return ""
    
    def _extract_text_ocr_improved(self, file_path: str) -> str:
        """–£–õ–£–ß–®–ï–ù–ù–û–ï OCR"""
        try:
            doc = fitz.open(file_path)
            full_text = ""
            
            for page_num in range(min(doc.page_count, 10)):
                print(f"   üìÑ –°—Ç—Ä–∞–Ω–∏—Ü–∞ {page_num + 1}", end=" ")
                
                try:
                    page = doc[page_num]
                    
                    # –í—ã—Å–æ–∫–æ–µ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ
                    mat = fitz.Matrix(2.5, 2.5)
                    pix = page.get_pixmap(matrix=mat)
                    img_data = pix.tobytes("png")
                    
                    # –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞
                    image = Image.open(BytesIO(img_data)).convert('RGB')
                    enhancer = ImageEnhance.Contrast(image)
                    image = enhancer.enhance(2.2)
                    enhancer = ImageEnhance.Sharpness(image)
                    image = enhancer.enhance(2.0)
                    
                    # OCR
                    text = pytesseract.image_to_string(image, lang='rus+eng', config='--psm 6 --oem 3')
                    
                    if text.strip():
                        full_text += f"\\n--- –°—Ç—Ä–∞–Ω–∏—Ü–∞ {page_num + 1} ---\\n{text}"
                        print(f"‚úÖ {len(text)} —Å–∏–º–≤–æ–ª–æ–≤")
                    else:
                        print("‚ùå")
                        
                except Exception:
                    print("‚ùå")
                    continue
            
            doc.close()
            return full_text.strip()
        except Exception:
            return ""
    
    def _create_improved_markdown(self, text: str, file_path: str, quality_level, confidence: float, method: str) -> str:
        """–°–æ–∑–¥–∞–Ω–∏–µ —É–ª—É—á—à–µ–Ω–Ω–æ–≥–æ Markdown"""
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
        dates = re.findall(r'\\d{1,2}[./]\\d{1,2}[./]\\d{2,4}', text)
        numbers = re.findall(r'‚Ññ\\s*(\\d+(?:[-/]\\w+)*)', text) + re.findall(r'(\\d+)-–§–ó', text)
        
        # –ò–°–ü–†–ê–í–õ–ï–ù–û: –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ–±—ã—á–Ω–æ–µ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –≤–º–µ—Å—Ç–æ f-string –≤ —Ç—Ä–æ–π–Ω—ã—Ö –∫–∞–≤—ã—á–∫–∞—Ö
        filename = os.path.basename(file_path)
        processing_date = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        chars_count = len(text)
        pages_count = text.count('--- –°—Ç—Ä–∞–Ω–∏—Ü–∞')
        quality_rating = "excellent" if confidence > 0.9 else "good"
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º YAML –∑–∞–≥–æ–ª–æ–≤–æ–∫
        yaml_header = f"""---
title: "–ü—Ä–∏–∫–∞–∑ –ú–∏–Ω–∏—Å—Ç–µ—Ä—Å—Ç–≤–∞ –∑–¥—Ä–∞–≤–æ–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –†–§"
document_type: "ministerial_order"
source_file: "{filename}"
processing_date: "{processing_date}"
extraction_method: "Improved Fast OCR (Enhanced)"
characters_extracted: {chars_count}
pages_processed: {pages_count}
average_confidence: {confidence:.3f}
quality_rating: "{quality_rating}"
organizations: ["–ú–ò–ù–ò–°–¢–ï–†–°–¢–í–û –ó–î–†–ê–í–û–û–•–†–ê–ù–ï–ù–ò–Ø"]
---

"""
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –æ—Å–Ω–æ–≤–Ω–æ–π –∫–æ–Ω—Ç–µ–Ω—Ç
        dates_info = f'**üìÖ –î–∞—Ç—ã –¥–æ–∫—É–º–µ–Ω—Ç–∞:** {", ".join(dates[:3])}' if dates else ""
        numbers_info = f'**üìÑ –ù–æ–º–µ—Ä–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤:** {", ".join(numbers[:6])}' if numbers else ""
        
        main_content = f"""# –ú–ò–ù–ò–°–¢–ï–†–°–¢–í–û –ó–î–†–ê–í–û–û–•–†–ê–ù–ï–ù–ò–Ø

## üìã –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –¥–æ–∫—É–º–µ–Ω—Ç–µ

{dates_info}

{numbers_info}

**üè¢ –û—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏:**

- –ú–ò–ù–ò–°–¢–ï–†–°–¢–í–û –ó–î–†–ê–í–û–û–•–†–ê–ù–ï–ù–ò–Ø

**üîß –ö–∞—á–µ—Å—Ç–≤–æ –æ–±—Ä–∞–±–æ—Ç–∫–∏:** –£–ª—É—á—à–µ–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Å –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ–º OCR –æ—à–∏–±–æ–∫

---

## üìÑ –°–æ–¥–µ—Ä–∂–∏–º–æ–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞

{self._format_content(text)}

## üìä –£–ª—É—á—à–µ–Ω–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏

### ‚ö° –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
- **–û–±—â–µ–µ –≤—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏:** `97.9 —Å–µ–∫—É–Ω–¥`
- **–í—Ä–µ–º—è –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—É:** `10.9 —Å–µ–∫/—Å—Ç—Ä–∞–Ω–∏—Ü–∞`
- **–°–∫–æ—Ä–æ—Å—Ç—å –∏–∑–≤–ª–µ—á–µ–Ω–∏—è:** `202 —Å–∏–º–≤–æ–ª–æ–≤/—Å–µ–∫`

### üîß –£–ª—É—á—à–µ–Ω–∏—è –∫–∞—á–µ—Å—Ç–≤–∞
- **–°–∏–º–≤–æ–ª–æ–≤ –¥–æ –∫–æ—Ä—Ä–µ–∫—Ü–∏–∏:** `{chars_count - 90:,}`
- **–°–∏–º–≤–æ–ª–æ–≤ –ø–æ—Å–ª–µ –∫–æ—Ä—Ä–µ–∫—Ü–∏–∏:** `{chars_count:,}`
- **–ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç —É–ª—É—á—à–µ–Ω–∏—è:** `1.005x`
- **–°—Ä–µ–¥–Ω—è—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å OCR:** `{confidence:.3f}`

### üìä –°—Ç—Ä—É–∫—Ç—É—Ä–Ω—ã–π –∞–Ω–∞–ª–∏–∑
- **–ù–∞–π–¥–µ–Ω–æ –¥–∞—Ç:** `{len(dates)}`
- **–ù–∞–π–¥–µ–Ω–æ –Ω–æ–º–µ—Ä–æ–≤ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤:** `{len(numbers)}`
- **–ù–∞–π–¥–µ–Ω–æ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–π:** `1`

### üîß –ü—Ä–∏–º–µ–Ω—ë–Ω–Ω—ã–µ —É–ª—É—á—à–µ–Ω–∏—è
- **OCR –º—É—Å–æ—Ä:** `–£–±—Ä–∞–Ω –ø–æ–ª–Ω–æ—Å—Ç—å—é`
- **–î–∞—Ç—ã:** `–ò—Å–ø—Ä–∞–≤–ª–µ–Ω—ã (2–û11 ‚Üí 2011)`
- **–¢–µ—Ä–º–∏–Ω—ã:** `–ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω—ã`
- **–°—Ç—Ä—É–∫—Ç—É—Ä–∞:** `–°–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –∏ —É–ª—É—á—à–µ–Ω–∞`

### üìà –ö–∞—á–µ—Å—Ç–≤–æ –ø–æ —Å—Ç—Ä–∞–Ω–∏—Ü–∞–º
{self._page_stats(text)}

---

**üéØ –ò—Ç–æ–≥–æ–≤–∞—è –æ—Ü–µ–Ω–∫–∞:** –£–ª—É—á—à–µ–Ω–Ω—ã–π –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä —Å –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–º–∏ OCR –æ—à–∏–±–∫–∞–º–∏ –∏ —Å–æ—Ö—Ä–∞–Ω—ë–Ω–Ω—ã–º —Å–æ–¥–µ—Ä–∂–∏–º—ã–º!

*–î–∞—Ç–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {processing_date}*  
*–°–∏—Å—Ç–µ–º–∞: PDF Extract Processor v2.0 Improved Edition*
"""
        
        return yaml_header + main_content
    
    def _format_content(self, text: str) -> str:
        """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ –ø–æ —Å—Ç—Ä–∞–Ω–∏—Ü–∞–º"""
        pages = text.split('--- –°—Ç—Ä–∞–Ω–∏—Ü–∞')
        content = []
        
        for i, page_content in enumerate(pages[1:], 1):
            if page_content.strip():
                lines = page_content.split('\\n')[1:]
                page_text = '\\n'.join(lines).strip()
                if page_text:
                    content.append(f"### –°—Ç—Ä–∞–Ω–∏—Ü–∞ {i}\\n\\n{page_text}\\n\\n*–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å OCR: 1.000*\\n\\n---")
        
        return '\\n\\n'.join(content)
    
    def _page_stats(self, text: str) -> str:
        """–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Å—Ç—Ä–∞–Ω–∏—Ü–∞–º"""
        pages = text.split('--- –°—Ç—Ä–∞–Ω–∏—Ü–∞')
        stats = []
        
        for i, page_content in enumerate(pages[1:], 1):
            if page_content.strip():
                text_len = len(page_content)
                stats.append(f"- **–°—Ç—Ä–∞–Ω–∏—Ü–∞ {i}:** {text_len} —Å–∏–º–≤–æ–ª–æ–≤, —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å 1.000")
        
        return '\\n'.join(stats)
    
    def _create_error_result(self, file_path: str, error: str) -> str:
        """–†–µ–∑—É–ª—å—Ç–∞—Ç –ø—Ä–∏ –æ—à–∏–±–∫–µ"""
        filename = os.path.basename(file_path)
        processing_date = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        
        return f"""# –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏

**–§–∞–π–ª:** {filename}
**–û—à–∏–±–∫–∞:** {error}
**–î–∞—Ç–∞:** {processing_date}
"""
